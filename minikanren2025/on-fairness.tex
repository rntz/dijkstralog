\documentclass[acmsmall,screen,review,anonymous,dvipsnames,svgnames]{acmart}
\usepackage[utf8]{inputenc}

%\title{Monotonic, Bounded, Fair}
%% GEB: EGB reference how?
%\subtitle{miniKanren's power as inspiration; its limits as implementation}
%\subtitle{The power of miniKanren as inspiration; the limitations of miniKanren as implementation}

%\title{Worst-case optimal joins as fair conjunctions}
%\title{Fair, bounded, worst-case optimal joins}
\title{Fair intersection of seekable iterators}

\author{Michael Arntzenius}
\email{rntz@berkeley.edu}
\orcid{0009-0002-2234-2549}
\affiliation{%
	\institution{UC Berkeley}
	\city{Berkeley}
	\state{CA}
	\country{USA}
}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}


%% Packages & commands
\usepackage{minted}
\setminted{
  %% linenos,
  xleftmargin=1.5em,
  listparameters=\setlength{\topsep}{0.5em},
  %% %% bgcolor=AliceBlue,
  %% %% bgcolor=Gainsboro,
  %% %% bgcolor=OldLace,
  %% %% bgcolor=Cornsilk,
  %% bgcolor=Beige,
  %% bgcolorpadding=0.5em,
}
\setmintedinline{bgcolor=none,bgcolorpadding=0pt}
% try listparameters=... to set left margin?

\newcommand\hask[1]{\mintinline{haskell}{#1}}
\newcommand\ttt\texttt

\newcommand\todo[1]{{\color{Orange}#1}}
\newcommand\XXX{\todo{XXX}}


\begin{document}

\begin{abstract}
  {miniKanren}'s key semantic advance over Prolog is to implement a complete yet efficient search strategy, fairly interleaving execution between disjuncts.
  This fairness is accomplished by bounding how much work is done exploring one disjunct before switching to the next.
  We show that the same idea -- fairness via bounded work -- underlies an elegant compositional approach to implementing worst-case optimal joins using a seekable iterator interface, suitable for shallow embedding in functional languages.
\end{abstract}

\maketitle

\section{Fair union of streams}
%\section{Fair, bounded disjunction}

If there are multiple rules applicable to the current goal, Prolog tries them in order, exploring each to exhaustion before starting the next.
If exploring a rule fails to terminate, later rules are not visited, and any potential solutions they could have generated are lost.
%We might blame this on Prolog doing \emph{depth-first} search, which can get ``trapped'' exploring an infinite subtree and fail to return to explore its siblings.
If we think of goal-directed search as yielding a stream of solutions, Prolog implements disjunction (between multiple rules) as stream concatenation.
In Haskell, taking advantage of laziness to represent possibly-infinite streams, we might implement this like so:

\begin{minted}{haskell}
data Stream a = Empty
              | Yield a (Stream a)
append Empty        ys = ys
append (Yield x xs) ys = Yield x (append xs ys)         -- keep focus on xs
\end{minted}

\noindent
As we've hinted, stream concatenation is an incomplete search strategy: \ttt{append xs ys} will never visit \ttt{ys} if \ttt{xs} is infinite.
We can fix this by interleaving \ttt{xs} and \ttt{ys} instead:

\begin{minted}{haskell}
interleave Empty        ys = ys
interleave (Yield x xs) ys = Yield x (interleave ys xs) -- swap focus to ys
\end{minted}

\noindent
However, this is only complete if all streams involved are \emph{productive,} meaning that evaluation to weak head normal form always yields a constructor (\hask{Empty} or \hask{Yield}) without looping indefinitely.
It's easy to define unproductive streams recursively, for instance:

\begin{minted}{haskell}
theAnswer :: Stream Int
theAnswer = interleave theAnswer (Yield 42 Empty)
\end{minted}

%% TODO: explain semantics, xs = xs ∪ {42}. Usual semantics is xs is the least set satisfying this, so xs = {42}; but *whatever* xs is, we definitely have 42 ∈ xs since 42 ∈ {42} ⇒ 42 ∈ xs ∪ {42} ⇒ 42 ∈ xs. But our approach here won't discover that; so it's not complete.

\noindent
Our difficulty is that, ideally, we would like the union of streams to be productive if \emph{any} input stream is.
Neither concatenation nor interleaving has this property, and in fact, standard programming language evaluation orders (whether lazy or eager) cannot express fairly interleaving evaluation between two sub-expressions: we must pick one to examine first; if that one is unproductive, further evaluation is blocked.%
\footnote{The classic example here is ``parallel or'', a hypothetical function \hask{por :: Bool -> Bool -> Bool} implementing boolean disjunction \emph{fairly,} meaning \hask{(por True undefined) == (por undefined True) == True}.}
%
The standard solution, used in e.g.~\textmu{}Kanren~\citep{muKanren}, is to extend \hask{Stream} with an extra constructor, \hask{Later},\footnotemark\ which exposes the existence of intermediate evaluation steps without giving any further information:

\begin{minted}{haskell}
data Stream a = Empty
              | Yield a (Stream a)
              | Later   (Stream a)
\end{minted}

\noindent
This makes it easy to ensure \emph{all} definitions are productive: simply guard any recursion with \hask{Later}.
\todo{TODO: cite guarded (co-)recursion.}
For instance, if we replace the canonical unproductive recursive definition, \hask{let xs = xs}, with a guarded one, \hask{let xs = Later xs}, examining \ttt{xs} will no longer cause an unrecoverable infinite loop; instead it will immediately yield \hask{Later xs}.
Thus \hask{Later} acts as an explicit signal to the consumer, permitting it to switch to evaluating some other stream if it so wishes.
We can use this to implement fairly interleaving stream union (\textmu{}Kanren's \ttt{mplus}):

\footnotetext{In \citet{muKanren} these are ``immature'' streams, represented as procedures of zero arguments.}

\begin{minted}{haskell}
union Empty        ys = ys
union (Yield x xs) ys = Yield x (union xs ys)  -- keep focus on xs
union (Later xs)   ys = Later   (union ys xs)  -- swap focus to ys
\end{minted}

\noindent
As long as we are careful to guard all recursion with \hask{Later}, we can now define \ttt{theAnswer} completely:

\begin{minted}{haskell}
theAnswer :: Stream Int
theAnswer = union (Later theAnswer) (Yield 42 Empty)
-- Equivalent to an infinite stream of interleaved Later & Yield 42:
-- theAnswer = Later (Yield 42 theAnswer)
\end{minted}

\noindent
\todo{%
  TODO: explain this in terms of \emph{bounded work} instead of \emph{productivity}.
  (For instance, in the absence of any \hask{Later}s, this degenerates to concatenation; we are relying on \hask{Later} for completeness even if all streams are productive.)
  Explain that by guarding with \hask{Later}, we ensure a bounded amount of work is done before we hit a \hask{Later}.
  This means that switching only when we see \hask{Later} is fair, and therefore complete.
  Our design recipe, then, is to carefully \emph{bound} the work we do in any given search step, allowing us to \emph{fairly interleave} search steps.
  In minikanren this is used to ensure \emph{completeness.}
  As we're about to see, it can also be used to ensure \emph{performance.}
}

%% X and Y
%% --> evaluate X, it becomes (X1 : Xrest)
%% --> Y[X1] or (Xrest and Y)

In this paper, we show how to apply a similar trick, but for \emph{conjunctive} queries -- in particular, database joins.
We will take the implementation of \emph{leapfrog intersection of seekable iterators} used in the worst-case optimal join algorithm Leapfrog Triejoin~\citep{lftj}, and show that it is \emph{not} fair.
To remedy this, we show how to extend the seekable iterator interface to allow \emph{bounded interleaving} between sub-iterators.

\todo{TODO: cite indexed streams as well}


%% \section{sketches}
%% \todo{TODO SKETCHES}

%% miniKanren's key idea over Prolog is to have a complete search strategy by using a FAIR strategy for disjunctions.
%% We accomplish this by BOUNDING the time we spend in each disjunct before switching to the other.

%% FAIR: no branch gets ``starved'' by another branch; with enough time, we investigate all branches arbitrarily far.

%% BOUNDED: we try a branch for only a bounded amount of time, so that we don't get STUCK. This is the purpose of the ``thunk'' constructor for streams (what's the standard name for this in mK?).

%% Two uses of fairness:

%% 1. Implementing $\lambda_{\vee}$.
%%    semantics are nondeterministic,
%%    so SEARCH!

%%    This search is inefficient because it fails to take into account the *monotonic structure* of evaluation in lambda join: we are in essence branching on *how precise* to make our evaluation.
%%    The branching is not between mutually exclusive alternatives, where each contributes information the other lacks, but where one alternative has strictly more information than another.

%%    (how does this actually result in combinatorial explosion, though?)

%% 2. Work in progress on a seekable iterator interface for compositionally worst-case optimal joins.
%%    The key idea is to FAIRLY incorporate information from all iterators contributing to the join,
%%    which we do by BOUNDING how much work we put into one iterator before moving to the next.

%%    This implements FAIR CONJUNCTION, and it's FAST.

%%    But it takes advantage of having a comprehensive view of data, so we can scan through it in sorted order - we can't define these things recursively, therefore it can't be turing-complete.
%% if we decide to use ``feedback with delay'' to overcome this, we have perhaps reinvented, not miniKanren, but Datalog!


\section{Unfair intersection of seekable iterators}

\todo{Explain that intersection of sorted sets is both a special case of, and an ingredient in the implementation of, database joins.}

Let us assume our data is sorted and allows efficiently seeking forward to find the next key-value pair whose key is at least some lower bound (by e.g.\ galloping search).
We can capture these assumptions in a \emph{seekable iterator} interface:

\begin{minted}{haskell}
data Iter k v = Empty
              | Yield k v (k -> Iter k v)
\end{minted}

\noindent
A seekable iterator, \hask{Iter k v}, is like a stream of key-value pairs, \hask{Stream (k,v)}, except that (a) it yields pairs in ascending key order, and (b) rather than the \emph{entire} remainder of the stream, \hask{Yield} produces a function \hask{seek :: k -> Iter k v} which seeks forward to its argument; i.e.\ \ttt{seek target} iterates over all remaining pairs with keys \ttt{k >= target}.
%
To iterate over \emph{all} pairs, we repeatedly \ttt{seek} toward the just-visited key:

\begin{minted}{haskell}
toSorted :: Iter k v -> [(k, v)]
toSorted Empty = []
toSorted (Yield k v seek) = (k,v) : toSorted (seek k)
\end{minted}

\noindent
Given a sorted list \hask{[(k, v)]}, we can easily produce a seekable iterator for it, although seeking will not be efficient since Haskell lists allow only linear, in-order access.
We could use a more appropriate data structure, such as a sorted array or balanced tree, but omit this as it is not crucial to our explanation:

\begin{minted}{haskell}
fromSorted :: Ord k => [(k, v)] -> Iter k v
fromSorted [] = Empty
fromSorted ((k,v) : rest) = Yield k v seek
  where seek k' = fromSorted (dropWhile ((< k') . fst) rest)
\end{minted}

\noindent
Finally, we can intersect two seekable iterators by leapfrogging: repeatedly advance the iterator at the smaller key towards the higher, until either both iterators reach the same key (an element of the intersection) or one is exhausted (the intersection is empty):

\begin{minted}{haskell}
intersect :: Ord k => Iter k a -> Iter k b -> Iter k (a,b)
intersect Empty _ = Empty
intersect _ Empty = Empty
intersect s@(Yield k1 x s') t@(Yield k2 y t') =
  case compare k1 k2 of
    LT -> intersect (s' k2) t -- s < t, so seek s toward t
    GT -> intersect s (t' k1) -- t < s, so seek t toward s
    EQ -> Yield k1 (x,y) (\k' -> intersect (s' k') (t' k'))
\end{minted}

\noindent
So far, so good.
However, \ttt{intersect} is not \emph{fair,} and this can cause performance to suffer asymptotically when intersecting more than two iterators.
For instance, consider three subsets of the integers between 0 and 7,777,777 --- the evens, the odds, and the endpoints:

\begin{minted}{haskell}
evens = fromSorted [(x, "even") | x <- [0, 2 .. 7_777_777]]
odds  = fromSorted [(x, "odd")  | x <- [1, 3 .. 7_777_777]]
ends  = fromSorted [(x, "end")  | x <- [0,      7_777_777]]
\end{minted}

\noindent
The intersection of \ttt{evens} and \ttt{odds}, and therefore of all three sets, is empty.
We can compute this using \ttt{intersect}, but performance is \emph{dramatically} better if we avoid intersecting \ttt{evens} and \ttt{odds} directly by intersecting with \ttt{ends} first.
At the GHCi repl:

\begin{minted}{haskell}
ghci> -- set +s to print time statistics
ghci> :set +s
ghci> toSorted ((evens `intersect` odds) `intersect` ends)
[]
(5.57 secs, 5,288,958,128 bytes)
ghci> toSorted (evens `intersect` (odds `intersect` ends))
[]
(0.57 secs, 248,961,040 bytes)
\end{minted}

\noindent
The reason is simple: ``leapfrogging'' \ttt{evens} and \ttt{odds} against one another alternates between each relation until both are exhausted; whatever our current key $x$ in \ttt{even} (e.g.\ $x = 1$), we seek forward past $x$ in \ttt{odds} and reach $x+1$; then we seek past $x+1$ in \ttt{even} to $x + 2$, and so on.
We must do 7,777,777 units of work before we can determine that the intersection is empty.
%
By contrast, intersecting \ttt{odds} with \ttt{ends} will almost immediately skip to the end of both relations.
(This occurs even though we are \emph{not} materializing any intermediate results.)%
\footnotemark{}

\footnotetext{
  We are telling a white lie here: because we are using Haskell lists, in which seeking is linear-time, there is no \emph{asymptotic} slow-down in this particular example; we are instead observing the difference between an \emph{interpreted} inner loop (\ttt{intersect}, loaded at the GHCi repl) and a \emph{compiled} one (\ttt{dropWhile} from the standard library).
  But had we used sorted arrays with binary or galloping search, or balanced trees, there would be a genuine asymptotic speed-up, for the reasons we describe.
}

The trouble, of course, is that \ttt{intersect} does not (and, with our current \hask{Iter} interface, \emph{cannot}) fairly interleave work between its subiterators.
Instead, like \ttt{interleave}, it blocks first on one, then the other.
For precisely this reason leapfrog intersection is usually formulated as an $n$-way operation (e.g.\ in \citet{lftj}). \XXX

\todo{cleanup this para.}
We have failed to capture in a compositional way the essence of leapfrog intersection, which is \emph{to communicate lower bounds on keys between the intersected iterators.}
When intersecting two iterators, we propagate information back and forth between them: the key we find in the first becomes our target in the second, and vice versa.
But in \ttt{(evens `intersect` odds) `intersect` ends}, before communicating any information to or from \ttt{ends}, we first block waiting for \ttt{evens `intersect` odds} to find a key, which takes $O(n)$ work (where $n$ is the size of \ttt{evens}/\ttt{odds}).
This prevents useful information exchange between \ttt{ends} and \ttt{evens}/\ttt{odds}, which would let us skip this work and jump straight to the end in $O(1)$ time.
\noindent
\todo{Can we overcome this limitation?}

%% \begin{figure}
%%   \begin{minted}{haskell}
%%   data Iter k v = Empty
%%                 | Yield k v (k -> Iter k v)

%%   fromSorted :: Ord k => [(k, v)] -> Iter k v
%%   fromSorted [] = Empty
%%   fromSorted ((k,v) : rest) = Yield k v seek
%%     where seek k' = fromSorted (dropWhile ((< k') . fst) rest)

%%   toSorted :: Iter k v -> [(k, v)]
%%   toSorted Empty = []
%%   toSorted (Yield k v s) = (k,v) : toSorted (s k)

%%   intersect :: Ord k => Iter k a -> Iter k b -> Iter k (a,b)
%%   intersect Empty _ = Empty
%%   intersect _ Empty = Empty
%%   intersect s@(Yield k1 x s') t@(Yield k2 y t') =
%%     case compare k1 k2 of
%%       LT -> intersect (s' k2) t -- s < t, so seek s toward t
%%       GT -> intersect s (t' k1) -- t < s, so seek t toward s
%%       EQ -> Yield k1 (x,y) (\k' -> s' k' `intersect` t' k')
%%   \end{minted}
%%   \caption{Unfair intersection of seekable iterators}
%%   \label{fig:unfair-iterators}
%% \end{figure}


\section{Fair intersection of seekable iterators}
%\section{Worst-case optimal iteration as bounded, fair conjunction}

\begin{figure}
  \begin{minted}{haskell}
  data Bound k
    = Init             -- anything satisfies this bound
    | Atleast k        -- is it >= k?
    | Greater k        -- is it  > k?
    | Done             -- nothing satisfies this bound
    deriving Eq

  data Position k v
    = Found k v        -- here's a key and its value
    | Bound (Bound k)  -- the next key satisfies this bound

  data Seek k v = Seek
    { posn :: Position k v          -- a key-value pair, or a bound
    , seek :: Bound k -> Seek k v } -- seeks forward toward a bound

  -- Init < ... < Atleast n < Greater n < Atleast (n+1) < ... < Done
  instance Ord k => Ord (Bound k) where
    compare x y = embed x `compare` embed y
      where embed Init        = (0, Nothing)
            embed (Atleast k) = (1, Just (k, 0))
            embed (Greater k) = (1, Just (k, 1))
            embed Done        = (2, Nothing)

  bound :: Seek k v -> Bound k
  bound (Seek (Found k v) _) = Atleast k
  bound (Seek (Bound p)   _) = p

  fromSorted :: Ord k => [(k, v)] -> Iter k v
  fromSorted l = Iter posn seek where
    posn = case l of [] -> Bound Done; (k,v):_ -> Found k v
    seek target = fromSorted $ dropWhile ((target >) . Atleast . fst) l

  toSorted :: Iter k v -> [(k, v)]
  toSorted (Iter (Bound Done) _)    = []
  toSorted (Iter (Found k v)  seek) = (k, v) : toSorted (seek (Greater k))
  toSorted (Iter (Bound k)    seek) = toSorted (seek k)

  intersect :: Ord k => Seek k a -> Seek k b -> Seek k (a,b)
  intersect s t = Seek posn' seek' where
    posn' | Found k x <- posn s, Found k' y <- posn t, k == k' = Found k (x, y)
          | otherwise = Bound (bound s `max` bound t)
    seek' k = intersect s' t' where
      s' = seek1 k
      t' = seek2 (bound s') -- leapfrog optimization; could be (seek2 k) instead
  \end{minted}
  \caption{Fair intersection of seekable iterators}
  \label{fig:fair-iterators}
\end{figure}


%% ---------- BIBLIOGRAPHY ----------
\bibliography{on-fairness}

\end{document}
